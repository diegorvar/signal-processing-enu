{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e35d403",
   "metadata": {},
   "source": [
    "Libraries Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "8da0f4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "9affcfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "import imageio\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c165370",
   "metadata": {},
   "source": [
    "Helper Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "38ae00dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '/Users/dlugardo/Desktop/data/ENU_v2' # path to the folder with the data \n",
    "\n",
    "def get_data(location):\n",
    "    file_name = str(location) + '.ENU.txt'\n",
    "    path = os.path.join(data_folder, file_name)\n",
    "\n",
    "    if os.path.isfile(path):\n",
    "        data = np.loadtxt(path, skiprows=2)\n",
    "    else:\n",
    "        file_name = str(location) + '_ENU.txt'\n",
    "        path = os.path.join(data_folder, file_name)\n",
    "\n",
    "        if os.path.isfile(path):\n",
    "            data = np.loadtxt(path, skiprows=2)\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Neither '{location}.ENU.txt' nor '{location}_ENU.txt' found in {data_folder}\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "8595860a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decimal_year_to_date(decimal_year):\n",
    "    \"\"\"\n",
    "    Converts a decimal year to a datetime.date object.\n",
    "    \"\"\"\n",
    "    year = int(decimal_year)\n",
    "    fractional_part = decimal_year - year\n",
    "\n",
    "    # Determine if it's a leap year for accurate day calculation\n",
    "    is_leap = (year % 4 == 0 and year % 100 != 0) or (year % 400 == 0)\n",
    "    days_in_year = 366 if is_leap else 365\n",
    "\n",
    "    # Calculate the number of days from the start of the year\n",
    "    days_offset = fractional_part * days_in_year\n",
    "\n",
    "    # Create a datetime object for January 1st of that year\n",
    "    start_of_year = datetime.date(year, 1, 1)\n",
    "\n",
    "    # Add the calculated offset in days\n",
    "    result_date = start_of_year + datetime.timedelta(days=days_offset)\n",
    "\n",
    "    return result_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "0e54af81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevation_m</th>\n",
       "      <th>is_greenland</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NGFJ</td>\n",
       "      <td>80.568475</td>\n",
       "      <td>-16.841131</td>\n",
       "      <td>35.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JWLF</td>\n",
       "      <td>83.111656</td>\n",
       "      <td>-45.119847</td>\n",
       "      <td>112.9</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>THU4</td>\n",
       "      <td>76.537106</td>\n",
       "      <td>-68.824953</td>\n",
       "      <td>36.2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JGBL</td>\n",
       "      <td>82.208758</td>\n",
       "      <td>-31.004208</td>\n",
       "      <td>753.3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>THU2</td>\n",
       "      <td>76.537047</td>\n",
       "      <td>-68.825050</td>\n",
       "      <td>36.2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>MIK2</td>\n",
       "      <td>68.140281</td>\n",
       "      <td>-31.451825</td>\n",
       "      <td>815.9</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>KUAQ</td>\n",
       "      <td>68.587000</td>\n",
       "      <td>-33.052750</td>\n",
       "      <td>865.2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>KSUT</td>\n",
       "      <td>64.070697</td>\n",
       "      <td>-52.007697</td>\n",
       "      <td>40.7</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>RINK</td>\n",
       "      <td>71.848500</td>\n",
       "      <td>-50.993967</td>\n",
       "      <td>1337.9</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>NRSK</td>\n",
       "      <td>79.155031</td>\n",
       "      <td>-17.725419</td>\n",
       "      <td>348.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   station   latitude  longitude  elevation_m  is_greenland\n",
       "0     NGFJ  80.568475 -16.841131         35.5          True\n",
       "1     JWLF  83.111656 -45.119847        112.9          True\n",
       "2     THU4  76.537106 -68.824953         36.2          True\n",
       "3     JGBL  82.208758 -31.004208        753.3          True\n",
       "4     THU2  76.537047 -68.825050         36.2          True\n",
       "..     ...        ...        ...          ...           ...\n",
       "71    MIK2  68.140281 -31.451825        815.9          True\n",
       "72    KUAQ  68.587000 -33.052750        865.2          True\n",
       "73    KSUT  64.070697 -52.007697         40.7          True\n",
       "74    RINK  71.848500 -50.993967       1337.9          True\n",
       "75    NRSK  79.155031 -17.725419        348.0          True\n",
       "\n",
       "[76 rows x 5 columns]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StationMetaData = df = pd.read_csv('/Users/dlugardo/Documents/GitHub/signal-processing-enu/GreenlandStations.csv')\n",
    "StationMetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "62a599cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Skipping NGFJ: continuous segment too short.\n",
      "  → File not found for station THU4. Skipping.\n",
      "  → File not found for station QENU. Skipping.\n",
      "  → File not found for station AAS2. Skipping.\n",
      "  → Skipping EQNU: continuous segment too short.\n",
      "  → Skipping ISOR: continuous segment too short.\n",
      "  → Skipping TIMM: continuous segment too short.\n",
      "  → Skipping KLY2: continuous segment too short.\n",
      "  → Skipping SCOB: continuous segment too short.\n",
      "  → File not found for station SCO4. Skipping.\n",
      "  → File not found for station STNO. Skipping.\n",
      "  → File not found for station QAQ2. Skipping.\n",
      "  → File not found for station KLQ3. Skipping.\n",
      "  → Skipping KULU: continuous segment too short.\n",
      "  → Skipping UPAK: continuous segment too short.\n",
      "  → Skipping AVAN: continuous segment too short.\n",
      "  → Skipping KAPI: continuous segment too short.\n",
      "  → Skipping THU1: continuous segment too short.\n",
      "  → File not found for station THU3. Skipping.\n",
      "  → Skipping NUNA: continuous segment too short.\n",
      "  → File not found for station KSUT. Skipping.\n"
     ]
    }
   ],
   "source": [
    "## LTM Creation\n",
    "from datetime import timedelta\n",
    "\n",
    "stations_names_with_data = []\n",
    "metadata_records = []\n",
    "\n",
    "MAX_GAP_DAYS = 14  # maximum acceptable gap (in days)\n",
    "\n",
    "def find_longest_continuous_segment(dates, max_gap_days=14):\n",
    "    # Ensure dates are sorted\n",
    "    dates = np.sort(dates)\n",
    "    segments = []\n",
    "    current_segment = [dates[0]]\n",
    "\n",
    "    for i in range(1, len(dates)):\n",
    "        if (dates[i] - dates[i-1]).days <= max_gap_days:\n",
    "            current_segment.append(dates[i])\n",
    "        else:\n",
    "            segments.append(current_segment)\n",
    "            current_segment = [dates[i]]\n",
    "    segments.append(current_segment)\n",
    "\n",
    "    # Return the longest continuous segment\n",
    "    return max(segments, key=len)\n",
    "\n",
    "for station_name in StationMetaData.station:\n",
    "    try:\n",
    "        raw_data = get_data(station_name)\n",
    "        time = raw_data[:, 0]\n",
    "        converted_dates = np.array([decimal_year_to_date(dy) for dy in time])\n",
    "\n",
    "        # Find longest continuous segment of data\n",
    "        continuous_segment = find_longest_continuous_segment(converted_dates, max_gap_days=MAX_GAP_DAYS)\n",
    "\n",
    "        if len(continuous_segment) < 365 * 5:  # optional: skip if segment is too short\n",
    "            print(f\"  → Skipping {station_name}: continuous segment too short.\")\n",
    "            continue\n",
    "\n",
    "        # Filter both data and error to this segment\n",
    "        mask = np.isin(converted_dates, continuous_segment)\n",
    "        data = raw_data[mask, 1:4]\n",
    "        error = raw_data[mask, 4:]\n",
    "        converted_dates = converted_dates[mask]\n",
    "        \n",
    "        # Detrend data\n",
    "        data_detrended = scipy.signal.detrend(data, axis=0)\n",
    "\n",
    "        # Build DataFrame\n",
    "        df = pd.DataFrame({'time': converted_dates})\n",
    "        df['east'] = data_detrended[:, 0]\n",
    "        df['north'] = data_detrended[:, 1]\n",
    "        df['up'] = data_detrended[:, 2]\n",
    "        df.set_index('time', inplace=True)\n",
    "\n",
    "        # Compute monthly climatology\n",
    "        df['month_day'] = df.index.map(lambda x: x.strftime('%m-%d'))\n",
    "        df = df[df['month_day'] != '02-29']\n",
    "        climatology_daily = df.groupby('month_day')[['east', 'north', 'up']].mean()\n",
    "    \n",
    "        climatology_daily.to_csv('/Users/dlugardo/Documents/GitHub/signal-processing-enu/LTM/files/' + station_name + '_DailyLTM.csv', index = True) \n",
    "        \n",
    "        start_date = continuous_segment[0]\n",
    "        end_date = continuous_segment[-1]\n",
    "        duration_years = round((end_date - start_date).days / 365.25, 2)\n",
    "\n",
    "        metadata_records.append({\n",
    "            'station': station_name,\n",
    "            'start_date': start_date.strftime('%Y-%m-%d'),\n",
    "            'end_date': end_date.strftime('%Y-%m-%d'),\n",
    "            'years_of_data': duration_years\n",
    "        })\n",
    "\n",
    "        stations_names_with_data.append(station_name)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  → File not found for station {station_name}. Skipping.\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"  → Error processing station {station_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "#metadata_df = pd.DataFrame(metadata_records)\n",
    "#metadata_df.to_csv('/Users/dlugardo/Documents/GitHub/signal-processing-enu/LTM/LTM_station_metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "165fd894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Skipping NGFJ: continuous segment too short.\n",
      "  → File not found for station THU4. Skipping.\n",
      "  → File not found for station QENU. Skipping.\n",
      "  → File not found for station AAS2. Skipping.\n",
      "  → Skipping EQNU: continuous segment too short.\n",
      "  → Skipping ISOR: continuous segment too short.\n",
      "  → Skipping TIMM: continuous segment too short.\n",
      "  → Skipping KLY2: continuous segment too short.\n",
      "  → Skipping SCOB: continuous segment too short.\n",
      "  → File not found for station SCO4. Skipping.\n",
      "  → File not found for station STNO. Skipping.\n",
      "  → File not found for station QAQ2. Skipping.\n",
      "  → File not found for station KLQ3. Skipping.\n",
      "  → Skipping KULU: continuous segment too short.\n",
      "  → Skipping UPAK: continuous segment too short.\n",
      "  → Skipping AVAN: continuous segment too short.\n",
      "  → Skipping KAPI: continuous segment too short.\n",
      "  → Skipping THU1: continuous segment too short.\n",
      "  → File not found for station THU3. Skipping.\n",
      "  → Skipping NUNA: continuous segment too short.\n",
      "  → File not found for station KSUT. Skipping.\n"
     ]
    }
   ],
   "source": [
    "## LTM Creation\n",
    "from datetime import timedelta\n",
    "\n",
    "stations_names_with_data = []\n",
    "metadata_records = []\n",
    "\n",
    "MAX_GAP_DAYS = 14  # maximum acceptable gap (in days)\n",
    "\n",
    "def find_longest_continuous_segment(dates, max_gap_days=14):\n",
    "    # Ensure dates are sorted\n",
    "    dates = np.sort(dates)\n",
    "    segments = []\n",
    "    current_segment = [dates[0]]\n",
    "\n",
    "    for i in range(1, len(dates)):\n",
    "        if (dates[i] - dates[i-1]).days <= max_gap_days:\n",
    "            current_segment.append(dates[i])\n",
    "        else:\n",
    "            segments.append(current_segment)\n",
    "            current_segment = [dates[i]]\n",
    "    segments.append(current_segment)\n",
    "\n",
    "    # Return the longest continuous segment\n",
    "    return max(segments, key=len)\n",
    "\n",
    "for station_name in StationMetaData.station:\n",
    "    try:\n",
    "        raw_data = get_data(station_name)\n",
    "        time = raw_data[:, 0]\n",
    "        converted_dates = np.array([decimal_year_to_date(dy) for dy in time])\n",
    "\n",
    "        # Find longest continuous segment of data\n",
    "        continuous_segment = find_longest_continuous_segment(converted_dates, max_gap_days=MAX_GAP_DAYS)\n",
    "\n",
    "        if len(continuous_segment) < 365 * 5:  # optional: skip if segment is too short\n",
    "            print(f\"  → Skipping {station_name}: continuous segment too short.\")\n",
    "            continue\n",
    "\n",
    "        # Filter both data and error to this segment\n",
    "        mask = np.isin(converted_dates, continuous_segment)\n",
    "        data = raw_data[mask, 1:4]\n",
    "        error = raw_data[mask, 4:]\n",
    "        converted_dates = converted_dates[mask]\n",
    "        \n",
    "        # Detrend data\n",
    "        data_detrended = scipy.signal.detrend(data, axis=0)\n",
    "\n",
    "        # Build DataFrame\n",
    "        df = pd.DataFrame({'time': converted_dates})\n",
    "        df['east'] = data_detrended[:, 0]\n",
    "        df['north'] = data_detrended[:, 1]\n",
    "        df['up'] = data_detrended[:, 2]\n",
    "        df.set_index('time', inplace=True)\n",
    "\n",
    "        df_rolling = df.rolling(window=15, center=True, min_periods=10).mean()\n",
    "\n",
    "        # Drop rows with NaNs resulting from the rolling average\n",
    "        df_rolling = df_rolling.dropna()\n",
    "\n",
    "        # Compute monthly climatology (LTM)\n",
    "        df_rolling['month_day'] = df_rolling.index.map(lambda x: x.strftime('%m-%d'))\n",
    "        df_rolling = df_rolling[df_rolling['month_day'] != '02-29']\n",
    "        climatology_daily = df_rolling.groupby('month_day')[['east', 'north', 'up']].mean()\n",
    "\n",
    "        climatology_daily.to_csv('/Users/dlugardo/Documents/GitHub/signal-processing-enu/LTM/files/' + station_name + '_Daily15RollingLTM.csv', index = True)  \n",
    "        stations_names_with_data.append(station_name)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  → File not found for station {station_name}. Skipping.\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"  → Error processing station {station_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "#metadata_df = pd.DataFrame(metadata_records)\n",
    "#metadata_df.to_csv('/Users/dlugardo/Documents/GitHub/signal-processing-enu/LTM/LTM_station_metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "21b77576",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (800, 1100) to (800, 1104) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    }
   ],
   "source": [
    "Time_days =  pd.read_csv('/Users/dlugardo/Documents/GitHub/signal-processing-enu/LTM/files/SRMP_DailyLTM.csv').month_day\n",
    "\n",
    "cmap = cm.coolwarm_r\n",
    "vmin = -8  # or use np.nanmin of all station 'up' values if precomputed\n",
    "vmax = 8   # same as above\n",
    "norm = colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "\n",
    "filenames = []  \n",
    "\n",
    "for n, month_day in enumerate(Time_days):\n",
    "    fig= plt.figure(figsize=(8,11))\n",
    "    ax = plt.axes(projection=ccrs.Stereographic())\n",
    "    plt.title(\"Deterended LTM Daily Average Station Displacement Vectors  \" + str(month_day))\n",
    "\n",
    "    ax.set_extent([-55, -5, 55, 90])\n",
    "    ax.gridlines(draw_labels=True)\n",
    "    ax.stock_img()\n",
    "    ax.coastlines(resolution='10m', alpha = 0.3)\n",
    "\n",
    "    for station in stations_names_with_data:\n",
    "        climatology_daily = pd.read_csv('/Users/dlugardo/Documents/GitHub/signal-processing-enu/LTM/files/' + station + '_DailyLTM.csv')\n",
    "        \n",
    "        smdt = StationMetaData.loc[StationMetaData['station'] == station]\n",
    "\n",
    "        lon = smdt.longitude\n",
    "        lat = smdt.latitude\n",
    "\n",
    "        ax.plot(lon, lat, marker='o', color='black', markersize=2, alpha=0.6, transform=ccrs.Geodetic())\n",
    "        \n",
    "        U = np.array([climatology_daily['east'].iloc[n]])\n",
    "        V = np.array([climatology_daily['north'].iloc[n]])\n",
    "        C = np.array(climatology_daily['up'].iloc[n]) \n",
    "\n",
    "        scale_factor = 12\n",
    "\n",
    "        ax.quiver(\n",
    "            lon, lat, U , V ,\n",
    "            [C],  # color mapped by vertical component\n",
    "            scale=scale_factor,\n",
    "            transform=ccrs.PlateCarree(),\n",
    "            cmap=cmap,\n",
    "            norm=norm,\n",
    "            width=0.005,\n",
    "            alpha=1,\n",
    "            edgecolor='k',\n",
    "            linewidth=0.5,\n",
    "            headwidth=2,         # smaller width\n",
    "            headlength=2,        # smaller length\n",
    "            headaxislength=2.5\n",
    "        )\n",
    "        magnitude = np.sqrt(U**2 + V**2)\n",
    "        #print(f\"{station} @ {month}: U={U}, V={V}, Mag={magnitude}\")\n",
    "\n",
    "\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])  # only needed for colorbar\n",
    "    cbar = plt.colorbar(sm, ax=ax, orientation='vertical', shrink=0.6, pad=0.02)\n",
    "    cbar.set_label('Vertical Displacement (mm)')\n",
    "\n",
    "\n",
    "    ref_mm = 1  # reference displacement in mm\n",
    "    ref_units = ref_mm  # length in plot units\n",
    "\n",
    "    Q = ax.quiver(\n",
    "        np.array([0]), np.array([0]),\n",
    "        np.array([1]), np.array([0]),\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        scale=scale_factor,\n",
    "    )\n",
    "\n",
    "    ax.quiverkey(\n",
    "        Q,\n",
    "        X=0.55, Y=-0.1, U=ref_units,\n",
    "        label=f'{ref_mm} mm',\n",
    "        labelpos='E',\n",
    "        coordinates='axes'\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    filename = f'/Users/dlugardo/Documents/GitHub/signal-processing-enu/Visualization/PlotsforAnimations/LTM_MapVis_{month_day}.png'\n",
    "    plt.savefig(filename)\n",
    "    filenames.append(filename)\n",
    "    plt.close()\n",
    "    \n",
    "with imageio.get_writer('/Users/dlugardo/Documents/GitHub/signal-processing-enu/Visualization/LTM_MapVis_Daily.gif', mode='I', duration=20) as writer:\n",
    "    for filename in filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "\n",
    "with imageio.get_writer('/Users/dlugardo/Documents/GitHub/signal-processing-enu/Visualization/LTM_MapVis_Daily.mp4' , fps=12) as writer:\n",
    "    for filename in filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a048c687",
   "metadata": {},
   "source": [
    "### Rolling Average 50 Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "e5c776d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_day</th>\n",
       "      <th>east</th>\n",
       "      <th>north</th>\n",
       "      <th>up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-01</td>\n",
       "      <td>-0.205351</td>\n",
       "      <td>-0.138121</td>\n",
       "      <td>1.902454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01-02</td>\n",
       "      <td>-0.196900</td>\n",
       "      <td>-0.246734</td>\n",
       "      <td>2.069685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-03</td>\n",
       "      <td>-0.230167</td>\n",
       "      <td>-0.145070</td>\n",
       "      <td>1.955248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01-04</td>\n",
       "      <td>-0.219732</td>\n",
       "      <td>-0.086218</td>\n",
       "      <td>1.515121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01-05</td>\n",
       "      <td>-0.233246</td>\n",
       "      <td>-0.157136</td>\n",
       "      <td>1.901002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>12-27</td>\n",
       "      <td>-0.158374</td>\n",
       "      <td>-0.100594</td>\n",
       "      <td>2.033309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>12-28</td>\n",
       "      <td>-0.169545</td>\n",
       "      <td>-0.104004</td>\n",
       "      <td>1.955992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>12-29</td>\n",
       "      <td>-0.176557</td>\n",
       "      <td>-0.116668</td>\n",
       "      <td>1.925529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>12-30</td>\n",
       "      <td>-0.185414</td>\n",
       "      <td>-0.137576</td>\n",
       "      <td>1.879490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>12-31</td>\n",
       "      <td>-0.183421</td>\n",
       "      <td>-0.146651</td>\n",
       "      <td>1.886628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>365 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    month_day      east     north        up\n",
       "0       01-01 -0.205351 -0.138121  1.902454\n",
       "1       01-02 -0.196900 -0.246734  2.069685\n",
       "2       01-03 -0.230167 -0.145070  1.955248\n",
       "3       01-04 -0.219732 -0.086218  1.515121\n",
       "4       01-05 -0.233246 -0.157136  1.901002\n",
       "..        ...       ...       ...       ...\n",
       "360     12-27 -0.158374 -0.100594  2.033309\n",
       "361     12-28 -0.169545 -0.104004  1.955992\n",
       "362     12-29 -0.176557 -0.116668  1.925529\n",
       "363     12-30 -0.185414 -0.137576  1.879490\n",
       "364     12-31 -0.183421 -0.146651  1.886628\n",
       "\n",
       "[365 rows x 4 columns]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climatology_daily = pd.read_csv('/Users/dlugardo/Documents/GitHub/signal-processing-enu/LTM/files/SRMP_DailyRollingLTM.csv')\n",
    "climatology_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "09c300eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (800, 1100) to (800, 1104) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    }
   ],
   "source": [
    "Time_days =  pd.read_csv('/Users/dlugardo/Documents/GitHub/signal-processing-enu/LTM/files/SRMP_DailyLTM.csv').month_day\n",
    "\n",
    "cmap = cm.coolwarm_r\n",
    "vmin = -7  # or use np.nanmin of all station 'up' values if precomputed\n",
    "vmax = 7   # same as above\n",
    "norm = colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "\n",
    "filenames = []  \n",
    "\n",
    "for n, month_day in enumerate(Time_days):\n",
    "    fig= plt.figure(figsize=(8,11))\n",
    "    ax = plt.axes(projection=ccrs.Stereographic())\n",
    "    plt.title(\"Deterended LTM Daily Average (15 Days Rolled Average) Displacement \" + str(month_day))\n",
    "\n",
    "    ax.set_extent([-55, -5, 55, 90])\n",
    "    ax.gridlines(draw_labels=True)\n",
    "    ax.stock_img()\n",
    "    ax.coastlines(resolution='10m', alpha = 0.3)\n",
    "\n",
    "    for station in stations_names_with_data:\n",
    "        climatology_daily = pd.read_csv('/Users/dlugardo/Documents/GitHub/signal-processing-enu/LTM/files/' + station + '_Daily15RollingLTM.csv')\n",
    "        smdt = StationMetaData.loc[StationMetaData['station'] == station]\n",
    "\n",
    "        lon = smdt.longitude\n",
    "        lat = smdt.latitude\n",
    "\n",
    "        ax.plot(lon, lat, marker='o', color='black', markersize=2, alpha=0.6, transform=ccrs.Geodetic())\n",
    "        \n",
    "        U = np.array([climatology_daily['east'].iloc[n]])\n",
    "        V = np.array([climatology_daily['north'].iloc[n]])\n",
    "        C = np.array(climatology_daily['up'].iloc[n]) \n",
    "\n",
    "        scale_factor = 12\n",
    "\n",
    "        ax.quiver(\n",
    "            lon, lat, U , V ,\n",
    "            [C],  # color mapped by vertical component\n",
    "            scale=scale_factor,\n",
    "            transform=ccrs.PlateCarree(),\n",
    "            cmap=cmap,\n",
    "            norm=norm,\n",
    "            width=0.005,\n",
    "            alpha=1,\n",
    "            edgecolor='k',\n",
    "            linewidth=0.5,\n",
    "            headwidth=2,         # smaller width\n",
    "            headlength=2,        # smaller length\n",
    "            headaxislength=2.5\n",
    "        )\n",
    "        magnitude = np.sqrt(U**2 + V**2)\n",
    "        #print(f\"{station} @ {month}: U={U}, V={V}, Mag={magnitude}\")\n",
    "\n",
    "\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])  # only needed for colorbar\n",
    "    cbar = plt.colorbar(sm, ax=ax, orientation='vertical', shrink=0.6, pad=0.02)\n",
    "    cbar.set_label('Vertical Displacement (mm)')\n",
    "\n",
    "\n",
    "    ref_mm = 1  # reference displacement in mm\n",
    "    ref_units = ref_mm  # length in plot units\n",
    "\n",
    "    Q = ax.quiver(\n",
    "        np.array([0]), np.array([0]),\n",
    "        np.array([1]), np.array([0]),\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        scale=scale_factor,\n",
    "    )\n",
    "\n",
    "    ax.quiverkey(\n",
    "        Q,\n",
    "        X=0.55, Y=-0.1, U=ref_units,\n",
    "        label=f'{ref_mm} mm',\n",
    "        labelpos='E',\n",
    "        coordinates='axes'\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    filename = f'/Users/dlugardo/Documents/GitHub/signal-processing-enu/Visualization/PlotsforAnimations/LTM_MapVis_{month_day}_15Rolling.png'\n",
    "    plt.savefig(filename)\n",
    "    filenames.append(filename)\n",
    "    plt.close()\n",
    "    \n",
    "with imageio.get_writer('/Users/dlugardo/Documents/GitHub/signal-processing-enu/Visualization/LTM_MapVis_Daily15Rolling.gif', mode='I', duration=20) as writer:\n",
    "    for filename in filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "\n",
    "with imageio.get_writer('/Users/dlugardo/Documents/GitHub/signal-processing-enu/Visualization/LTM_MapVis_Daily15Rolling.mp4' , fps=12) as writer:\n",
    "    for filename in filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed065bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
