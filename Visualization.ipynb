{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0b2a9e1",
   "metadata": {},
   "source": [
    "# Data Visualization\n",
    "By Intern: Diego Varela, Mentor: Surendra Adhikari"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e35d403",
   "metadata": {},
   "source": [
    "Libraries Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "8da0f4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "9affcfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "import imageio\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c165370",
   "metadata": {},
   "source": [
    "Helper Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "38ae00dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '/Users/dlugardo/Desktop/data/ENU_v2' # path to the folder with the data \n",
    "\n",
    "def get_data(location):\n",
    "    file_name = str(location) + '.ENU.txt'\n",
    "    path = os.path.join(data_folder, file_name)\n",
    "\n",
    "    if os.path.isfile(path):\n",
    "        data = np.loadtxt(path, skiprows=2)\n",
    "    else:\n",
    "        file_name = str(location) + '_ENU.txt'\n",
    "        path = os.path.join(data_folder, file_name)\n",
    "\n",
    "        if os.path.isfile(path):\n",
    "            data = np.loadtxt(path, skiprows=2)\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Neither '{location}.ENU.txt' nor '{location}_ENU.txt' found in {data_folder}\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "8595860a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decimal_year_to_date(decimal_year):\n",
    "    \"\"\"\n",
    "    Converts a decimal year to a datetime.date object.\n",
    "    \"\"\"\n",
    "    year = int(decimal_year)\n",
    "    fractional_part = decimal_year - year\n",
    "\n",
    "    # Determine if it's a leap year for accurate day calculation\n",
    "    is_leap = (year % 4 == 0 and year % 100 != 0) or (year % 400 == 0)\n",
    "    days_in_year = 366 if is_leap else 365\n",
    "\n",
    "    # Calculate the number of days from the start of the year\n",
    "    days_offset = fractional_part * days_in_year\n",
    "\n",
    "    # Create a datetime object for January 1st of that year\n",
    "    start_of_year = datetime.date(year, 1, 1)\n",
    "\n",
    "    # Add the calculated offset in days\n",
    "    result_date = start_of_year + datetime.timedelta(days=days_offset)\n",
    "\n",
    "    return result_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "0e54af81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevation_m</th>\n",
       "      <th>is_greenland</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NGFJ</td>\n",
       "      <td>80.568475</td>\n",
       "      <td>-16.841131</td>\n",
       "      <td>35.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JWLF</td>\n",
       "      <td>83.111656</td>\n",
       "      <td>-45.119847</td>\n",
       "      <td>112.9</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>THU4</td>\n",
       "      <td>76.537106</td>\n",
       "      <td>-68.824953</td>\n",
       "      <td>36.2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JGBL</td>\n",
       "      <td>82.208758</td>\n",
       "      <td>-31.004208</td>\n",
       "      <td>753.3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>THU2</td>\n",
       "      <td>76.537047</td>\n",
       "      <td>-68.825050</td>\n",
       "      <td>36.2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>MIK2</td>\n",
       "      <td>68.140281</td>\n",
       "      <td>-31.451825</td>\n",
       "      <td>815.9</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>KUAQ</td>\n",
       "      <td>68.587000</td>\n",
       "      <td>-33.052750</td>\n",
       "      <td>865.2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>KSUT</td>\n",
       "      <td>64.070697</td>\n",
       "      <td>-52.007697</td>\n",
       "      <td>40.7</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>RINK</td>\n",
       "      <td>71.848500</td>\n",
       "      <td>-50.993967</td>\n",
       "      <td>1337.9</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>NRSK</td>\n",
       "      <td>79.155031</td>\n",
       "      <td>-17.725419</td>\n",
       "      <td>348.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   station   latitude  longitude  elevation_m  is_greenland\n",
       "0     NGFJ  80.568475 -16.841131         35.5          True\n",
       "1     JWLF  83.111656 -45.119847        112.9          True\n",
       "2     THU4  76.537106 -68.824953         36.2          True\n",
       "3     JGBL  82.208758 -31.004208        753.3          True\n",
       "4     THU2  76.537047 -68.825050         36.2          True\n",
       "..     ...        ...        ...          ...           ...\n",
       "71    MIK2  68.140281 -31.451825        815.9          True\n",
       "72    KUAQ  68.587000 -33.052750        865.2          True\n",
       "73    KSUT  64.070697 -52.007697         40.7          True\n",
       "74    RINK  71.848500 -50.993967       1337.9          True\n",
       "75    NRSK  79.155031 -17.725419        348.0          True\n",
       "\n",
       "[76 rows x 5 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StationMetaData = df = pd.read_csv('/Users/dlugardo/Documents/GitHub/signal-processing-enu/GreenlandStations.csv')\n",
    "StationMetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "647f34a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201, 3)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = StationMetaData.station[0]\n",
    "a\n",
    "var = get_data(a)\n",
    "time = var[:,0]\n",
    "data = var[:,1:4]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a599cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Skipping NGFJ: continuous segment too short.\n",
      "  → File not found for station THU4. Skipping.\n",
      "  → File not found for station QENU. Skipping.\n",
      "  → File not found for station AAS2. Skipping.\n",
      "  → Skipping EQNU: continuous segment too short.\n",
      "  → File not found for station SCO4. Skipping.\n",
      "  → File not found for station STNO. Skipping.\n",
      "  → File not found for station QAQ2. Skipping.\n",
      "  → File not found for station KLQ3. Skipping.\n"
     ]
    }
   ],
   "source": [
    "## LTM Creation\n",
    "from datetime import timedelta\n",
    "\n",
    "stations_names_with_data = []\n",
    "metadata_records = []\n",
    "\n",
    "MAX_GAP_DAYS = 14  # maximum acceptable gap (in days)\n",
    "\n",
    "def find_longest_continuous_segment(dates, max_gap_days=14):\n",
    "    # Ensure dates are sorted\n",
    "    dates = np.sort(dates)\n",
    "\n",
    "    segments = []\n",
    "    current_segment = [dates[0]]\n",
    "\n",
    "    for i in range(1, len(dates)):\n",
    "        if (dates[i] - dates[i-1]).days <= max_gap_days:\n",
    "            current_segment.append(dates[i])\n",
    "        else:\n",
    "            segments.append(current_segment)\n",
    "            current_segment = [dates[i]]\n",
    "    segments.append(current_segment)\n",
    "\n",
    "    # Return the longest continuous segment\n",
    "    return max(segments, key=len)\n",
    "\n",
    "for station_name in StationMetaData.station:\n",
    "    try:\n",
    "        raw_data = get_data(station_name)\n",
    "        time = raw_data[:, 0]\n",
    "        converted_dates = np.array([decimal_year_to_date(dy) for dy in time])\n",
    "\n",
    "        # Find longest continuous segment of data\n",
    "        continuous_segment = find_longest_continuous_segment(converted_dates, max_gap_days=MAX_GAP_DAYS)\n",
    "\n",
    "        if len(continuous_segment) < 365:  # optional: skip if segment is too short\n",
    "            print(f\"  → Skipping {station_name}: continuous segment too short.\")\n",
    "            continue\n",
    "        \n",
    "        # Filter both data and error to this segment\n",
    "        mask = np.isin(converted_dates, continuous_segment)\n",
    "        data = raw_data[mask, 1:4]\n",
    "        error = raw_data[mask, 4:]\n",
    "        converted_dates = converted_dates[mask]\n",
    "\n",
    "        # Detrend data\n",
    "        data_detrended = scipy.signal.detrend(data, axis=0)\n",
    "\n",
    "        # Build DataFrame\n",
    "        df = pd.DataFrame({'time': converted_dates})\n",
    "        df['east'] = data_detrended[:, 0]\n",
    "        df['north'] = data_detrended[:, 1]\n",
    "        df['up'] = data_detrended[:, 2]\n",
    "        df.set_index('time', inplace=True)\n",
    "\n",
    "        # Compute monthly climatology\n",
    "        df['month_day'] = df.index.map(lambda x: x.strftime('%m-%d'))\n",
    "        climatology = df.groupby('month_day')[['east', 'north', 'up']].mean()\n",
    "\n",
    "        df['month'] = df.index.map(lambda x: x.strftime('%m'))\n",
    "        climatology_monthly = df.groupby('month')[['east', 'north', 'up']].mean()\n",
    "\n",
    "        climatology_monthly.to_csv('/Users/dlugardo/Documents/GitHub/signal-processing-enu/LTM/' + station_name + '_LTM.csv', index = False) \n",
    "        \n",
    "        start_date = continuous_segment[0]\n",
    "        end_date = continuous_segment[-1]\n",
    "        duration_years = round((end_date - start_date).days / 365.25, 2)\n",
    "\n",
    "        metadata_records.append({\n",
    "            'station': station_name,\n",
    "            'start_date': start_date.strftime('%Y-%m-%d'),\n",
    "            'end_date': end_date.strftime('%Y-%m-%d'),\n",
    "            'years_of_data': duration_years\n",
    "        })\n",
    "\n",
    "        stations_names_with_data.append(station_name)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  → File not found for station {station_name}. Skipping.\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"  → Error processing station {station_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "metadata_df = pd.DataFrame(metadata_records)\n",
    "metadata_df.to_csv('/Users/dlugardo/Documents/GitHub/signal-processing-enu/LTM/LTM_station_metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b77576",
   "metadata": {},
   "outputs": [],
   "source": [
    "Time_months = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "\n",
    "cmap = cm.coolwarm_r\n",
    "vmin = -8  # or use np.nanmin of all station 'up' values if precomputed\n",
    "vmax = 8   # same as above\n",
    "norm = colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "\n",
    "filenames = []  \n",
    "\n",
    "for n, month in enumerate(Time_months):\n",
    "    fig= plt.figure(figsize=(8,11))\n",
    "    ax = plt.axes(projection=ccrs.Stereographic())\n",
    "    plt.title(\"LTM Station Displacement Vectors (East/North) \" + month)\n",
    "\n",
    "    ax.set_extent([-65, -5, 50, 90])\n",
    "    ax.gridlines(draw_labels=True)\n",
    "    ax.stock_img()\n",
    "    ax.coastlines(resolution='10m', alpha = 0.3)\n",
    "\n",
    "    for station in stations_names_with_data:\n",
    "        climatology_monthly = pd.read_csv('/Users/dlugardo/Documents/GitHub/signal-processing-enu/LTM/' + station + '_LTM.csv')\n",
    "        if climatology_monthly.shape[0] == 12:\n",
    "            smdt = StationMetaData.loc[StationMetaData['station'] == station]\n",
    "\n",
    "            lon = smdt.longitude\n",
    "            lat = smdt.latitude\n",
    "\n",
    "            ax.plot(lon, lat, marker='o', color='black', markersize=2, alpha=0.6, transform=ccrs.Geodetic())\n",
    "            \n",
    "            U = np.array([climatology_monthly['east'].iloc[n]])\n",
    "            V = np.array([climatology_monthly['north'].iloc[n]])\n",
    "            C = np.array(climatology_monthly['up'].iloc[n]) \n",
    "\n",
    "\n",
    "            scale_factor = 15\n",
    "\n",
    "            ax.quiver(\n",
    "                lon, lat, U , V ,\n",
    "                [C],  # color mapped by vertical component\n",
    "                scale=scale_factor,\n",
    "                transform=ccrs.PlateCarree(),\n",
    "                cmap=cmap,\n",
    "                norm=norm,\n",
    "                width=0.005,\n",
    "                alpha=1,\n",
    "                edgecolor='k',\n",
    "                linewidth=0.5,\n",
    "                headwidth=2,         # smaller width\n",
    "                headlength=2,        # smaller length\n",
    "                headaxislength=2.5\n",
    "            )\n",
    "            magnitude = np.sqrt(U**2 + V**2)\n",
    "            print(f\"{station} @ {month}: U={U}, V={V}, Mag={magnitude}\")\n",
    "        else:\n",
    "            #print(station + ' has no full LTM data.')\n",
    "            continue\n",
    "\n",
    "\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])  # only needed for colorbar\n",
    "    cbar = plt.colorbar(sm, ax=ax, orientation='vertical', shrink=0.6, pad=0.02)\n",
    "    cbar.set_label('Vertical Displacement (mm)')\n",
    "\n",
    "\n",
    "    ref_mm = 1  # reference displacement in mm\n",
    "    ref_units = ref_mm  # length in plot units\n",
    "\n",
    "    Q = ax.quiver(\n",
    "        np.array([0]), np.array([0]),\n",
    "        np.array([1]), np.array([0]),\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        scale=scale_factor,\n",
    "    )\n",
    "\n",
    "    ax.quiverkey(\n",
    "        Q,\n",
    "        X=0.55, Y=-0.1, U=ref_units,\n",
    "        label=f'{ref_mm} mm',\n",
    "        labelpos='E',\n",
    "        coordinates='axes'\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    filename = f'/Users/dlugardo/Documents/GitHub/signal-processing-enu/LTM_MapVis_{month}.png'\n",
    "    plt.savefig(filename)\n",
    "    filenames.append(filename)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "with imageio.get_writer('/Users/dlugardo/Documents/GitHub/signal-processing-enu/LTM_MapVis_Annual.gif', mode='I', duration=20) as writer:\n",
    "    for filename in filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c9da9d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "with imageio.get_writer('/Users/dlugardo/Documents/GitHub/signal-processing-enu/LTM_MapVis_Annual.gif', mode='I', duration=0.01) as writer:\n",
    "    for filename in filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "ce52b6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (800, 1100) to (800, 1104) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "[rawvideo @ 0x7fa261a049c0] Stream #0: not enough frames to estimate rate; consider increasing probesize\n"
     ]
    }
   ],
   "source": [
    "with imageio.get_writer('/Users/dlugardo/Documents/GitHub/signal-processing-enu/LTM_MapVis_Annual.mp4' , fps=3) as writer:\n",
    "    for filename in filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67151c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
